
# üìù Publications 
## üéô Speech Synthesis

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2024</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**FreGrad: Lightweight and fast frequency-aware diffusion vocoder**](https://arxiv.org/abs/2401.10032)

__Tan Dat Nguyen__* , [Ji-Hoon Kim](https://sites.google.com/view/jhoonkim/)*, [Youngjoon Jang](https://art-jang.github.io/), [Jaehun Kim](https://smokedindia.notion.site/Jaehun-Kim-5006f1fc98004817885325241723f1e3?pvs=74), [Joon Son Chung+](https://mmai.io/joon/)
[**Demo page**](https://mm.kaist.ac.kr/projects/FreGrad/), [**Official Code**](https://github.com/kaistmm/fregrad) (<font color="red"> Oral Presentation </font>)
<!-- # ! This one has code for showing citation-->
<!-- [**Project Page**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- We employ discrete wavelet transform that helps FreGrad to operate on a simple and concise feature space.
- We design a frequency-aware dilated convolution and introduce a bag of tricks that boosts the generation quality of the proposed model.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICABDE 2021</div><img src='images/CalibStyelSpeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Calib-StyleSpeech: A Zero-shot Approach In Voice Cloning Of High Adaptive Text To Speech System With Imbalanced Dataset**](https://link.springer.com/chapter/10.1007/978-3-030-97610-1_6) (<font color="red"> Oral Presentation </font>)

__Nguyen Tan Dat__, Lam Quang Tuong, Nguyen Duc Dung

[**Demo page**](https://signofthefour.github.io/calib-stylespeech-demo/).

- We propose to use CLUB to minimize the mutual information between content embedding and style embedding.
- Our work well-perform on zero-shot scenerio even when using skew ASR dataset

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NAFOSTED 2021</div><img src='images/bahnar.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[*A Linguistic-based Transfer Learning Approach for Low-resource Bahnar Text-to-Speech*](https://ieeexplore.ieee.org/document/10013451) (<font color="red"> Oral Presentation </font>)

__Tan Dat Nguyen__, Quang Tuong Lam, Duc Hao Do, Huu Thuc Cai, Hoang Suong Nguyen, Thanh Hung Vo, Duc Dung Nguyen.

[**Demo page**](https://signofthefour.github.io/bahnar_demo/).

- We apply phonetic-based transfer learning approach to create Bahnar-Kriem (very low resource language) TTS model.

</div>
</div>